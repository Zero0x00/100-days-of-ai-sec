# Day 12
---
description: 
--- 
![Day 12 Poster](images/day12-poster.png)

Today I explored two of the simplest â€” yet surprisingly powerful â€” machine learning techniques:

ğŸ”¹ **K-Nearest Neighbors (KNN)**  
ğŸ”¹ **Clustering Algorithms** like K-Means

---

## ğŸ”¸ KNN â€“ Like asking your 3 closest neighbors for restaurant recommendations â€” and going with the majority.

- Doesnâ€™t scale well with large data (**lazy learning**)  
- Suffers from the **curse of dimensionality**  
- **Use Case**: Real-time classification, stock market forecasting, data pre-processing

---

## ğŸ”¸ Clustering â€“ Like sorting socks by color â€” no names, just similarity.

- Sensitive to initial conditions and number of clusters  
- Inability to handle categorical data  
- **Use Case**: Grouping similar logs across distributed DBs, customer segmentation, threat pattern discovery

---

## ğŸ§  Security Relevance

Both are intuitive, interpretable, and widely used in cybersecurity â€” for **anomaly detection**, **threat grouping**, and **log clustering**.  
But when **nearness = trust**, it opens the door to subtle â€” and dangerous â€” manipulations ğŸ‘‡

---

## ğŸ” Security Lens

### âš ï¸ Evasion via Distance Manipulation (KNN)

Attackers can subtly modify malicious inputs to appear close to benign ones â€” bypassing detection.

> ğŸ’¡ Example: Slightly altered malware that lives in the "neighborhood" of clean files.

---

### âš ï¸ Cluster Poisoning Attacks

In unsupervised setups, adversaries inject crafted data to **shift cluster centers** or **distort groupings**.

> ğŸ’¡ Example: Fake logs or reviews injected to confuse anomaly detectors.

---

### âš ï¸ Model Extraction Risks

KNN-based systems are **query-heavy** and **memory-based** â€” attackers can reconstruct training data if they know the distance metric.

> ğŸ’¡ Example: API misuse to reverse-engineer sensitive training sets.

---

## ğŸ“š Key References

- Jagielski et al. (2018): *Manipulating Machine Learning with Adversarial Clustering*  
- Tramer et al. (2016): *Model Extraction via Query Attacks*

---

## ğŸ’¬ Discussion Prompt

> Have you ever used clustering for log analysis or threat detection?  
> What was your biggest challenge?

---

## ğŸ“… Coming Up

**Naive Bayes** â€” and how its â€œstrong independenceâ€ assumption becomes an adversaryâ€™s playground ğŸ¯

---

## ğŸ”— Missed Day 11?

Catch up here: [https://lnkd.in/g3EwkEQA](https://lnkd.in/g3EwkEQA)

---

**#100DaysOfAISec - Day 12 Post**  
#AISecurity #MLSecurity #MachineLearningSecurity #KNN #Clustering #CyberSecurity #AIPrivacy #AdversarialML #LearningInPublic #100DaysChallenge #ArifLearnsAI #LinkedInTech