# Day 11 Dimensionality Reduction

***

![Day 11 Poster](images/day11-poster.png)

**Today I explored Dimensionality Reduction** â€” a vital step to make sense of high-dimensional data ðŸ“‰ðŸ”

***

## ðŸ” Analogy

> Imagine packing for a trip.\
> You have a massive wardrobe (your data), but your suitcase only fits 10 items.\
> So, you pick versatile clothes â€” a few that cover most needs (formal, casual, warm, cold).
>
> Thatâ€™s Dimensionality Reduction:\
> **Compressing a huge dataset into its most meaningful parts â€” minimizing loss while maximizing utility.**

***

## ðŸ”¹ Two Common Techniques

### âœ… PCA (Principal Component Analysis)

ðŸ§³ Like folding and layering smartly to save space, PCA finds directions (components) that capture the most variance (info).

* Linear method
* Great when data lies in neat, straight patterns

### âœ… t-SNE (t-distributed Stochastic Neighbor Embedding)

ðŸ§³ Like grouping clothes by outfits (shoes + formalwear), t-SNE clusters related data together.

* Non-linear
* Captures local relationships, distorts global structure
* Ideal for visualizing complex, high-dimensional datasets

***

## ðŸš€ These techniques help models:

* âœ… Train faster
* âœ… Generalize better
* âœ… Reveal hidden patterns

***

## ðŸ” Security Lens

### âš ï¸ Information Loss & Blind Spots

ðŸŽ’ You packed for summer, but forgot a raincoat.\
Rare threats (low variance) may get discarded â€” making your model blind to anomalies or attacks.

> "Low variance" â‰  "low importance" â€” especially in security contexts.

### âš ï¸ Feature Obfuscation by Attackers

ðŸŽ’ Attackers can embed malicious patterns in dimensions likely to be discarded or compressed â€” bypassing detection pipelines.

### âš ï¸ Inference Attacks on Embeddings

ðŸŽ’ It's like sharing a blurred photo of your bag â€” someone could still guess your travel habits from the outline of items.

t-SNE visualizations can leak structural info â€” attackers might infer relationships between users, labels, or features.\
These compressed representations, if exposed, can be mined or reversed to extract sensitive patterns or identities.

***

## ðŸ“š Key References

* Jolliffe (2002) â€“ _Principal Component Analysis_
* Carlini et al. (2020) â€“ _Extracting Training Data from Embeddings_
* [StatQuest: t-SNE, Clearly Explained](https://lnkd.in/gxUtRGk7)

***

## ðŸ’¬ Prompt

> Have you visualized your model with t-SNE?\
> What insights â€” or vulnerabilities â€” did you discover?

***

## ðŸ“… Tomorrow

We explore **KNN & Clustering** â€” the simplest ML algorithms and how attackers exploit proximity logic ðŸ”—ðŸ‘¥

***

## ðŸ”— Missed Day 10?

Catch up here: [https://lnkd.in/gMh3rr8b](https://lnkd.in/gMh3rr8b)

***

**#100DaysOfAISec - Day 11 Post**\
\#AISecurity #MLSecurity #MachineLearningSecurity #DimensionalityReduction #CyberSecurity #AIPrivacy #AdversarialML #LearningInPublic #100DaysChallenge #ArifLearnsAI #LinkedInTech
