# Day 16 Deep vs Shallow Models

***

![Day 16 Poster](images/day16-poster.png)

## ğŸ” Shallow vs. Deep Models â€” Whatâ€™s the Difference?

### ğŸ§  **Shallow Models (1â€“2 layers)**

Think logistic regression, decision trees, or simple SVMs.\
âœ… Easy to interpret\
âœ… Less prone to overfitting (especially with small datasets)\
âŒ Limited ability to capture complex patterns

***

### ğŸ§  **Deep Models (3+ hidden layers)**

These are your typical neural networks used in vision, NLP, and more.\
âœ… Excellent at learning abstract and nonlinear features\
âœ… Essential for modern AI tasks\
âŒ More prone to overfitting, adversarial attacks, and memorization risks

***

## ğŸ” Security Lens â€” Where Things Break

### 1ï¸âƒ£ Overfitting to Poisoned Data (Deep Models)

Deep models can **memorize** malicious training examples.\
ğŸ’¥ _Example_: Poison a single face in a dataset â†’ model always misidentifies that person.

### 2ï¸âƒ£ Gradient-Based Attacks

Deep models expose **smooth gradients**, perfect for crafting adversarial inputs.\
ğŸ’¥ _Example_: Slight pixel tweaks make a CNN label a â€œcatâ€ as â€œguacamole.â€

### 3ï¸âƒ£ Explainability Gaps

Deep models = **black boxes**. Hard to reason about decisions â†’ hard to audit for security.\
ğŸ’¥ _Risk_: Hidden backdoors via neuron triggers or malicious weight updates.

### 4ï¸âƒ£ Robustness Trade-Offs (Shallow Models)

Shallow models are more interpretable, but **fragile** in high-dimensional spaces.\
ğŸ’¥ _Example_: A basic spam detector using logistic regression can be tricked with obfuscation (like â€œfr33 mon3y!â€)

***

## ğŸ§© What Can Help?

* Defensive distillation
* Adversarial training
* Model explainability tools (e.g., **SHAP**, **LIME**)
* Regular audits of training data sources

***

### ğŸ“š References

* **Ilyas et al. (2019)** â€” â€œAdversarial Examples Are Not Bugs, They Are Featuresâ€
* **Madry et al. (2018)** â€” â€œTowards Deep Learning Models Resistant to Adversarial Attacksâ€

***

### ğŸ’¬ Question for You

Have you ever chosen a shallow model over a deep one to make it easier to audit or secure?

***

ğŸ“… **Tomorrow**: Hyperparameter Tuning â€” How optimizing accuracy can accidentally expose your model to attacks.

ğŸ”— Missed Day 15? [https://lnkd.in/dMrvK\_yt](https://lnkd.in/dMrvK_yt)

***

\#100DaysOfAISec #AISecurity #MLSecurity #MachineLearningSecurity #DeepModels #ShallowModels #CyberSecurity #AIPrivacy #AdversarialML #LearningInPublic #100DaysChallenge #ArifLearnsAI #LinkedInTech
