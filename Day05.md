---
description: Decision Trees & Random Forests â€” Easy to Understand, Easier to Exploit?
---

# Day 5 Decision Tree & Random Forest

***

![Day 05 Poster](images/day05-poster.png)

Today, I explored two classic ML algorithms that are **surprisingly interpretable â€” and surprisingly vulnerable** ğŸ‘€

***

## ğŸ”¹ Decision Trees

Think of them like "if-then" **flowcharts**.\
They split data step by step:

ğŸ‘‰ If credit score > 700 â†’ Approve loan\
ğŸ‘‰ Else if income is high & no late payments â†’ Approve\
ğŸ‘‰ Else â†’ Reject

Itâ€™s a **checklist-style** model â€” easy to understand, easy to debug.

***

## ğŸ”¹ Random Forests

Now imagine a **forest of decision trees**.\
Each tree sees a slightly different view of the data and gives its vote.

Out of 100 trees:\
ğŸ—³ 70 say â€œApproveâ€, 30 say â€œRejectâ€\
âœ… Final answer? Approve.

The **majority wins** â€” leading to better accuracy & reduced bias.

***

## ğŸ” Security Lens

### âš ï¸ Decision Tree Risks

* **Evasion Attacks** â€“ Tiny input tweaks can change the outcome.\
  ğŸ“Œ A spammer adjusts a few words slightly to bypass a spam filter â€” and it works.
* **Privacy Leakage** â€“ Trees can **memorize sensitive training data**.\
  ğŸ“Œ A medical model might reveal symptom patterns tied to real patients.

***

### âš ï¸ Random Forest Risks

* **Adversarial Examples** â€“ Even with many trees, crafted inputs can slip through.\
  ğŸ“Œ A malware sample crafted to fool all trees might evade detection entirely.
* **Data Poisoning** â€“ If attackers poison the training data, the entire forest learns **wrongly**.\
  ğŸ“Œ Injecting fake â€œbenignâ€ malware during training teaches the model to trust real threats.

***

## ğŸ“š References

â€¢ Kantchelian et al., 2016 â€“ _Evasion Attacks on Decision Trees_\
â€¢ Biggio et al., 2018 â€“ _Poisoning Attacks on Random Forests_\
â€¢ Yeom et al., 2019 â€“ _Privacy Risks in Tree Models_\
â€¢ [Bonus Read: Demystifying Decision Trees â€“ SapienceSpace](https://lnkd.in/dnHKFJsG)

***

## ğŸ’¬ Question

How do you **secure your ML models** from evasion or poisoning?

***

ğŸ“… **Tomorrow**: Iâ€™ll explore **Boosting** â€” and why making your model â€œstrongerâ€ might also make it **fragile** âš ï¸

ğŸ”— **Missed Day 4?** [Click here](https://lnkd.in/dW34C7cT)

***

**#100DaysOfAISec â€“ Day 5 Post**\
\#AISecurity #MLSecurity #DecisionTrees #CyberSecurity #AIPrivacy #AdversarialML #LearningInPublic #100DaysChallenge #ArifLearnsAI #LinkedInTech
